import requests
import webbrowser
import cv2
import numpy as np
import os
from PIL import Image
!pip install PyPDF2
import PyPDF
import re
import io
!pip install PyMuPDF
import fitz
***************
FILETYPE=".pdf"
def düzenle(url):
  return bs(requests.get(url).text, "html.parser")
def bölme_2(data):
  url=data
  liste_url=[]
  for link in düzenle(url).find_all('a'):
    file_link = link.get('href')
    if FILETYPE in file_link:
      liste_url.append(file_link)
      liste_url_2=liste_url[2*int(len(liste_url)/5):3*int(len(liste_url)/5)]
  return liste_url_2
  ***************
def arama_2(kişi,data):
  liste=[]
  for link in bölme_2(data):
    response=requests.get(link)
    try:
      with io.BytesIO(response.content) as open_pdf_file:
        read_pdf = PyPDF2.PdfFileReader(open_pdf_file)
        num_pages = read_pdf.getNumPages()
        for jj in range(read_pdf.numPages):
          if (re.search(kişi,read_pdf.getPage(jj).extractText().lower())!=None)==True:
            print(re.search(kişi,read_pdf.getPage(jj).extractText().lower()),jj)
            file_name = link.split('/')[-1]
            with open(file_name, 'wb') as file:
              response = requests.get(link)
              file.write(response.content)
              liste.append(file_name)
    except:
      print("gazete yok")
  return(liste)
  ***************
  def arama_2_çoklu(kişi,kişi_1,data):
  liste=[]
  for link in bölme_2(data):
    response=requests.get(link)
    try:
      with io.BytesIO(response.content) as open_pdf_file:
        read_pdf = PyPDF2.PdfFileReader(open_pdf_file)
        num_pages = read_pdf.getNumPages()
        for jj in range(read_pdf.numPages):
          if (((re.search(kişi,read_pdf.getPage(jj).extractText().lower())!=None)==True or (re.search(kişi_1,read_pdf.getPage(jj).extractText().lower())!=None)==True)) :
            print(re.search(kişi,read_pdf.getPage(jj).extractText().lower()),jj)
            print(re.search(kişi_1,read_pdf.getPage(jj).extractText().lower()),jj)
            file_name = link.split('/')[-1]
            with open(file_name, 'wb') as file:
              response = requests.get(link)
              file.write(response.content)
              liste.append(file_name)
    except:
      print("gazete yok")
  return(liste)
  ***************
bölme_2("http://nek.istanbul.edu.tr:4444/ekos/GAZETE/gazete.php?gazete=vatan")
arama_2("cahit arf","http://nek.istanbul.edu.tr:4444/ekos/GAZETE/gazete.php?gazete=vatan")
bölme_2("http://nek.istanbul.edu.tr:4444/ekos/GAZETE/gazete.php?gazete=vatan")
arama_2("mustafa inan","http://nek.istanbul.edu.tr:4444/ekos/GAZETE/gazete.php?gazete=vatan")
arama_2("ratip berker","http://nek.istanbul.edu.tr:4444/ekos/GAZETE/gazete.php?gazete=vatan")
arama_2("ratıb berker","http://nek.istanbul.edu.tr:4444/ekos/GAZETE/gazete.php?gazete=vatan")
arama_2("kerim erim","http://nek.istanbul.edu.tr:4444/ekos/GAZETE/gazete.php?gazete=vatan")
  ***************
  def flags_decomposer(flags):
    l = []
    if flags & 2 ** 0:
        l.append("superscript")
    if flags & 2 ** 1:
        l.append("italic")
    if flags & 2 ** 2:
        l.append("serifed")
    else:
        l.append("sans")
    if flags & 2 ** 3:
        l.append("monospaced")
    else:
        l.append("proportional")
    if flags & 2 ** 4:
        l.append("bold")
    return ", ".join(l)
   ***************
 def page_information(name,sayfa):
  doc = fitz.open(name)
  page = doc[sayfa]
  # read page text as a dictionary, suppressing extra spaces in CJK fonts
  blocks = page.get_text("dict", flags=11)["blocks"]
  a=[]
  for b in blocks: # iterate through the text blocks
    for l in b["lines"]: # iterate through the text lines
        for s in l["spans"]: # iterate through the text spans
            print("")
            font_properties = "Font: '%s' (%s), size %g, color #%06x" % (
            s["font"], # font name
            flags_decomposer(s["flags"]), # readable font flags
            s["size"], # font size
            s["color"], # font color
            )
            a.append(s)
  return a
   ***************
  def text_extraction(data,ad,soyad,sayfa):
  size=[]
  text=[]
  font=[]
  new_liste=[]
  for i in page_information(data,sayfa):
    aaa=list(i.values())
    size.append(aaa[0])
    text.append(aaa[6])
    font.append(aaa[2])
  try: 
    text_lower=[]
    for j in text:
      text_lower.append(j.lower())
    if (text_lower.index(soyad)-text_lower.index(ad)==1):
      index=text_lower.index(ad)
    for ii in range(len(text)):
      if ((size[index]+2 < size[ii]) or (size[index]-2 < size[ii])) and (font[index]!=font[ii]) and (int(size[index]+1)!=int(index) and ):
        new_liste.append(ii)
        df=pd.DataFrame(data = new_liste, columns=["sonuc"])
    extracted_text=""
    for kkk in text[df.values[df.values<index][-1]:df.values[df.values>index][0]]:
        extracted_text=extracted_text+kkk
    return extracted_text
  except:
    print("isim bulunmadı")
   ***************
   text_extraction('aksam_1942_tesrini_3',"kerim ","erim ", 2)
